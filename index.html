---
layout: landing
---
				<!-- Banner -->
					<section id="banner">
						<div class="inner">
							<img class="round-image" src="images/linkedin.png" alt=""><br><br>
							<p style="font-weight: bold; font-size: 40px;">{{ site.title }}</p>
							<p>{{ site.description | markdownify }}</p>
							<!--ul class="actions">
								<li><a href="#" class="button special">Activate</a></li>
							</ul-->
						</div>
						<canvas id="elements-canvas" style="position: fixed; top: 0px; left: 0px; opacity: 0.25;z-index: 0;"></canvas>

						<a class="s-xguide-down trans" href="#one"></a>
						<a class="s-xguide-down arrow-1 trans" href="#one"></a>
					</section>

				<!-- One -->
					<section id="one" class="wrapper style5 special" style="z-index: 1; position: relative;">
						<div class="inner">
							<header class="major">
								<h2> <font face="Georgia, serif" size="6" color="grey" style="italic">&#8220;</font> <font size="7" >A</font>bout<br />
								me <font face="Georgia, serif" size="6" color="grey" style="italic">&#8221;</font></h2>
								<p>I am a highly driven individual with over 10 years of research experience, deeply invested in the research, development, and deployment of cutting-edge Computer Vision (CV) and Machine Learning (ML) technologies. My work is centered around creating future disruptive applications, with key areas of focus including Surgical Robotics, Mixed Reality, and Autonomous Vehicles.</p>
							</header>
							<ul class="icons major">
								<li><img src="/images/ar1.png" height="50"/></li>
								<li><img src="/images/ar2.png" height="50"/></li>
								<li><img src="/images/ar3.png" height="50"/></li>
								<li><img src="/images/ar4.png" height="50"/></li>
							</ul>
						</div>
					</section>

					<!-- Timeline Start -->

					<section id="News" class="wrapper style4 special" style="z-index: 1; position: relative;">
						<div class="inner">
						<header class="major">
						<h2><font size="7" style="bold">N</font><font size="6" style="bold">ews </font></h2>
						</header>
						<div style="text-align: left;">
							&nbsp;2nd June 2023&emsp;&emsp;Organized the <a href="https://sites.google.com/view/icra2023av/home">ICRA 2023 Workshop on Scalable Autonomous Driving</a><br>
							17th June 2021&emsp;&emsp;Organized the <a href="https://www.self-driving-cars.org/tutorial">CVPR 2021 Tutorial: Frontiers in Data-driven Autonomous Driving</a><br>
							&nbsp;&nbsp;2nd Sep&nbsp; 2021&emsp;&emsp;I was granted a US patent <a href="https://patents.google.com/patent/US10914605B1/">Guided Batching</a> - a method for building city-scale HD maps<br>
							30th June 2021&emsp;&emsp;Two papers <a href="https://arxiv.org/abs/2105.12337">Data-driven Planner</a> and  <a href="ttps://arxiv.org/abs/2105.12332">SimNet</a> got accepted by ICRA 2021<br>
							25th June 2020&emsp;&emsp;We released the  <a href="https://paperswithcode.com/paper/one-thousand-and-one-hours-self-driving">Lyft Level 5 Prediction Dataset</a><br>
						</div>
						</div>
					</section>

					<!-- Timeline End -->

				<!-- Two -->
					<section id="two" class="wrapper style2 special" style="z-index: 1; position: relative;">
						<div class="inner">
							<header class="major">
								<h2><font size="7" style="bold">R</font><font size="6" style="bold">esearch </font><font size="7" style="bold">P</font><font size="6" style="bold">rojects</font></h2>
							</header>
							<section class="spotlight">
								<div class="image"><img src="images/av.gif" alt="" /></div><div class="content">
									<h3>Autonomous Driving Research</h3>
									<p><font size="2">[1] <b>L. Chen</b>, L. Platinsky, S. Speichert, etc "What data do we need for training an AV motion planner?", in International Conference on Robotics and Automation (ICRA) 2021<a href="https://arxiv.org/abs/2105.12337">[arXiv]</a></font></p>
									<p><font size="2">[2] L. Bergamini, Y. Ye, O Scheel, <b>L. Chen</b>, etc "SimNet: Learning Reactive Self-driving Simulations from Real-world Observations", in International Conference on Robotics and Automation (ICRA) 2021<a href="https://arxiv.org/abs/2105.12332">[arXiv]</a></font></p>
									<p><font size="2">[3] J. Houston, G. Zuidhof, L. Bergamini, Y. Ye, <b>L. Chen</b>, etc, "One thousand and one hours: Self-driving motion prediction dataset". In Conference on Robot Learning (CORL) 2021<a href="https://proceedings.mlr.press/v155/houston21a.html">[PDF]</a></font></p>
									<p><font size="2">[4] <b>L. Chen</b>, Guided Batching: A Method for generating 3D visual maps from multiple limited field of view image sensorsGuided Batching: A Method for generating 3D visual maps from multiple limited field of view image sensors, US Patent US10914605B1, Issued Feb 9, 2021<a href="https://patents.google.com/patent/US10914605B1/">[URL]</a></font></p>
								</div>
							</section>
							<section class="spotlight">
								<div class="image"><img src="images/mediAR.gif" alt="" /></div><div class="content">
									<h3>Augmented Reality / Robotics Surgery</h3>
									<p>Keywords: SLAM|Stereo Matching</p>
									<p><font size="2">[1] <b>L. Chen</b>, T Day, W. Tang, N. John, "Recent Developments and Future Challenges in Medical Mixed Reality", 16th IEEE International Symposium on Mixed and Augmented Reality (ISMAR), 2017<a href="https://arxiv.org/abs/1708.01225">[arXiv]</a></font></p>
									<p><font size="2">[2] <b>L. Chen</b>, W. Tang, N. John, "Real-time Geometry-Aware Augmented Reality in Minimally Invasive Surgery", 11th MICCAI workshop on Augmented Environments for Computer-Assisted Interventions (AECAI), 2017<a href="http://digital-library.theiet.org/content/journals/10.1049/htl.2017.0068">[PDF]</a></font></p>
									<p><font size="2">[3] <b>L. Chen</b>, W. Tang, N Jogn, T. Wan, J. Zhang, "SLAM-based Dense Surface Reconstruction in Monocular Minimally Invasive Surgery and its Application to Augmented Reality", Computer Methods and Programs in Biomedicine, 158, 135-146, 2018<a href="https://doi.org/10.1016/j.cmpb.2018.02.006">[PDF]</a></font></p>
								</div>
							</section>
							<section class="spotlight">
								<div class="image"><img src="images/semantics.gif" alt="" /></div><div class="content">
									<h3>Context-Aware Mixed Reality</h3>
									<p>Keywords: Deep Learning|SLAM|Metaverse</p>
									<p><font size="2">[4] <b>L. Chen</b>, W. Tang, N. John, T. Wan, J. Zhang, "Context-Aware Mixed Reality: A Learning-based Framework for Semantic-level Interaction",Computer Graphics Forum \& Eurographics 2020 (Oral Presentation)<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.13887?af=R">[arXiv]</a><a href="https://youtu.be/nqh3cntOpRo">[Video]</a></font></p>
									<p><font size="2">[5] <b>L. Chen</b>, K Francis, W. Tang, "Semantic Augmented Reality Environment with Material-Aware Physical Interactions", 16th IEEE International Symposium on Mixed and Augmented Reality (ISMAR), 2017<a href="https://arxiv.org/abs/1708.01208">[arXiv]</a></font></p>
								</div>
							</section>
							<section class="spotlight">
								<div class="image"><img src="images/cv.png" alt="" /></div><div class="content">
									<h3>Computer Vision Research</h3>
									<p>Keywords: CV|Deep Learning</p>
									<p><font size="2">[6] <b>L. Chen</b>, W. Tang, N. W. John, T. R. Wan and J. J. Zhang, "De-smokeGCN: Generative Cooperative Networks for Joint Surgical Smoke Detection and Removal", IEEE Transactions on Medical Imaging, vol. 39, no. 5, pp. 1615-1625<a href="https://arxiv.org/abs/1803.05530">[arXiv]</a></font></p>
									<p><font size="2">[7] <b>L. Chen</b>, W. Tang, N. W. John, "Self-Supervised Monocular Image Depth Learning and Confidence Estimation", Neurocomputing, 381, 272-281, 2020.<a href="https://arxiv.org/abs/1803.05530">[arXiv]</a></font></p>
									<p><font size="2">[8] W. Zhang, Y. Zhao, P. Breckon, <b>L. Chen</b>, "Noise robust image edge detection based upon the automatic anisotropic Gaussian kernels", Pattern Recognition, 63, 193-205, 2017.</font></p>
									<p><font size="2">[9] Q. Gao, T.R. Wan, W. Tang, <b>L. Chen</b>, "A Stable and Accurate Marker-less Augmented Reality Registration Method", In: 2017 International Conference on CYBERWORLDS, 20-22, 2017</font></p>
									<p><font size="2">[10] Q. Gao, T.R. Wan, W. Tang, <b>L. Chen</b> and K.B Zhang, 2017. "An Improved Augmented Reality Registration Method Based on Visual SLAM", In: Edutainment 2017, 26-27, 2017 </font></p>
								</div>
							</section>
							<section class="spotlight">
								<div class="image"><img src="images/mathruns.gif" alt="" /></div><div class="content">
									<h3>Just for fun &#128539;</h3>
									<p><font size="2">[11] L Chen and W. Tang, "MathRun: an adaptive mental arithmetic game using a quantitative performance model." 30th International BCS Human Computer Interaction Conference (BHCI), 2016<a href="http://ewic.bcs.org/content/ConWebDoc/56996">[PDF]</a><a href="https://www.youtube.com/watch?v=dyZRRGMVLpU">[Video]</a></font></p>
								</div>
							</section>
						</div>
					</section>

				<!-- Three -->
<!-- 					<section id="three" class="wrapper style3 special" style="z-index: 1; position: relative;">
						<div class="inner">
							<header class="major">
								<h2><font size="7" style="bold">S</font><font size="6" style="bold">kills &amp; </font><font size="7" style="bold">T</font><font size="6" style="bold">echniques</font><br /></h2>
								<!--p>I am a computer vision researcher and software developer</p-->
								<!--br />fringilla tincidunt. Nullam dui leo Aenean mi ligula, rhoncus ullamcorper.</p-->
							<!-- </header>
							<ul class="features">
								<li class="icon fa-code">
									<h3>Multi-platform Programming</h3>
									<p>Iâ€™m passionate about solving real-world problems with coding. I have more than 8 years multi-platform programming experience with C/C++, Python, Matlab and Golang in Windows and Linux. </p>
								</li>
								<li class="icon fa-flask">
									<h3>Research</h3>
									<p>I love research and always keep up with the latest research trend and paper. I have published 8 papers as the first author during my PhD including some of the most impactful journals and conferences such as IEEE Transactions on Medical Imaging (IF 7.81), Neurocomputing (IF 4.07), and IEEE International Symposium on Mixed and Augmented Reality (ISMAR), Eurographics (EG). </p>
								</li>
								<li class="icon fa-eye">
									<h3>Computer Vision</h3>
									<p>Computer Vision is one of the most impressive and fascinating technologies that I have learned and worked on. It is the door connecting the machine with our real world. So far, I have worked on many projects using computer vision, such as medical image processing, AR and Self-Driving. I have comprehensive knowledge and experience with computer vision algorithms in feature/object tracking, camera calibration, Structure from Motion (SfM) and Simultaneous Localization and Mapping(SLAM).</p>
								</li>
								<li class="icon fa-cubes">
									<h3>Deep Learning</h3>
									<p>I am keen on deep learning and believe it's the key to many future technologies such as AR and Self-Driving. I have extensive experience using Caffe and Tensorflow for object classification  (CNN), semantic segmentation(FCN, CRF-RNN) and reinforcement learning. I have completed and earned certificate of the Deep Learning Specialization coursera online course by Andrew Ng. <a href="https://www.coursera.org/account/accomplishments/records/QFUNYEEDN69X">[Certificate]</a></p>
								</li>
							</ul>
						</div>
					</section> --> -->

				<!-- CTA -->
					<section id="cta" class="wrapper styleme">
						<div class="inner" style="z-index: 1; position: relative;">
							<header>
								<h2>Contact Me</h2>
								<!--p>Aliquam ut ex ut augue consectetur interdum endrerit imperdiet amet eleifend fringilla.</p-->
							</header>
							<ul class="actions vertical">
								<li><a href="https://www.linkedin.com/in/long-chen-in/" onclick="ga('send', 'event', 'CV', 'download', 'download')" class="button fit special">Linkedin</a></li>
								<li><a href="mailto:alwaysunny@gmail.com" class="button fit">Email ME</a></li>
							</ul>
						</div>
					</section>
