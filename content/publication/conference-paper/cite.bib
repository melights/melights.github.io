@InProceedings{pmlr-v155-houston21a,
  title = 	 {One Thousand and One Hours: Self-driving Motion Prediction Dataset},
  author =       {Houston, John and Zuidhof, Guido and Bergamini, Luca and Ye, Yawei and Chen, Long and Jain, Ashesh and Omari, Sammy and Iglovikov, Vladimir and Ondruska, Peter},
  booktitle = 	 {Proceedings of the 2020 Conference on Robot Learning},
  pages = 	 {409--418},
  year = 	 {2021},
  editor = 	 {Kober, Jens and Ramos, Fabio and Tomlin, Claire},
  volume = 	 {155},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v155/houston21a/houston21a.pdf},
  url = 	 {https://proceedings.mlr.press/v155/houston21a.html},
  abstract = 	 {Motivated by the impact of large-scale datasets on ML systems we present the largest self-driving dataset for motion prediction to date, containing over 1,000 hours of data. This was collected by a fleet of 20 autonomous vehicles along a fixed route in Palo Alto, California, over a four-month period. It consists of 170,000 scenes, where each scene is 25 seconds long and captures the perception output of the self-driving system, which encodes the precise positions and motions of nearby vehicles, cyclists, and pedestrians over time. On top of this, the dataset contains a high-definition semantic map with 15,242 labelled elements and a high-definition aerial view over the area. We show that using a dataset of this size dramatically improves performance for key self-driving problems. Combined with the provided software kit, this collection forms the largest and most detailed dataset to date for the development of self-driving machine learning tasks, such as motion forecasting, motion planning and simulation.}
}

@inproceedings{chen2021data,
  title={What data do we need for training an av motion planner?},
  author={Chen, Long and Platinsky, Lukas and Speichert, Stefanie and Osi{\'n}ski, B{\l}a{\.z}ej and Scheel, Oliver and Ye, Yawei and Grimmett, Hugo and Del Pero, Luca and Ondruska, Peter},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1066--1072},
  year={2021},
  organization={IEEE}
}
@inproceedings{bergamini2021simnet,
  title={Simnet: Learning reactive self-driving simulations from real-world observations},
  author={Bergamini, Luca and Ye, Yawei and Scheel, Oliver and Chen, Long and Hu, Chih and Del Pero, Luca and Osi{\'n}ski, B{\l}a{\.z}ej and Grimmett, Hugo and Ondruska, Peter},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5119--5125},
  year={2021},
  organization={IEEE}
}
@inproceedings{chen2020context,
  title={Context-Aware Mixed Reality: A Learning-Based Framework for Semantic-Level Interaction},
  author={Chen, Long and Tang, Wen and John, Nigel W and Wan, Tao Ruan and Zhang, Jian J},
  booktitle={Computer Graphics Forum},
  volume={39},
  number={1},
  pages={484--496},
  year={2020}
}
@inproceedings{chen2017semantic,
  title={Semantic Augmented Reality Environment with Material-Aware Physical Interactions},
  author={Chen, Long and Francis, Karl and Tang, Wen},
  booktitle={The 16th IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  year={2017}
}

@inproceedings{chen2017recent,
  title={Recent Developments and Future Challenges in Medical Mixed Reality},
  author={Chen, Long and Day, Thomas and Tang, Wen and John, Nigel W},
  booktitle={The 16th IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  year={2017}
}

