---
title: 'One Thousand and One Hours: Self-driving Motion Prediction Dataset'
authors:
  - John Houston
  - Guido Zuidhof
  - Luca Bergamini
  - Yawei Ye
  - admin
  - Ashesh Jain
  - Sammy Omari
  - Vladimir Iglovikov
  - Peter Ondruska
date: '2021-11-16'
doi: ''
publishDate: '2021-01-01'
publication_types: ['conference']
publication: In *Proceedings of the 2020 Conference on Robot Learning (CoRL)*
abstract: "Motivated by the impact of large-scale datasets on ML systems we present the largest self-driving dataset for motion prediction to date, containing over 1,000 hours of data. This was collected by a fleet of 20 autonomous vehicles along a fixed route in Palo Alto, California, over a four-month period. It consists of 170,000 scenes, where each scene is 25 seconds long and captures the perception output of the self-driving system, which encodes the precise positions and motions of nearby vehicles, cyclists, and pedestrians over time. On top of this, the dataset contains a high-definition semantic map with 15,242 labelled elements and a high-definition aerial view over the area. We show that using a dataset of this size dramatically improves performance for key self-driving problems. Combined with the provided software kit, this collection forms the largest and most detailed dataset to date for the development of self-driving machine learning tasks, such as motion forecasting, motion planning and simulation."
url_pdf: 'https://proceedings.mlr.press/v155/houston21a/houston21a.pdf'
url_code: 'https://paperswithcode.com/dataset/lyft-level-5-prediction'
url_dataset: 'https://www.kaggle.com/competitions/lyft-motion-prediction-autonomous-vehicles/data'
url_video: 'https://www.youtube.com/watch?v=kr9Ig44OAJE&ab_channel=PeterOndr%C3%BA%C5%A1ka'
featured: false
tags: [featured]
image:
  caption: ''
  focal_point: ''
  preview_only: false
---
