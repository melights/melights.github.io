---
title: 'LingoQA: Video Question Answering for Autonomous Driving'
authors:
  - Ana-Maria Marcu
  - admin
  - Jan HÃ¼nermann
  - Alice Karnsund
  - Benoit Hanotte
  - Prajwal Chidananda
  - Saurabh Nair
  - Vijay Badrinarayanan
  - Alex Kendall
  - Jamie Shotton
  - Oleg Sinavski
date: '2023-12-21'
doi: ''
publishDate: '2023-12-21'
publication_types: ['preprint']
publication: In *arXiv preprint arXiv:2312.14115*
abstract: "Autonomous driving has long faced a challenge with public acceptance due to the lack of explainability in the decision-making process. Video question-answering (QA) in natural language provides the opportunity for bridging this gap. Nonetheless, evaluating the performance of Video QA models has proved particularly tough due to the absence of comprehensive benchmarks. To fill this gap, we introduce LingoQA, a benchmark specifically for autonomous driving Video QA. The LingoQA trainable metric demonstrates a 0.95 Spearman correlation coefficient with human evaluations. We introduce a Video QA dataset of central London consisting of 419k samples that we release with the paper. We establish a baseline vision-language model and run extensive ablation studies to understand its performance."
url_pdf: 'https://arxiv.org/pdf/2312.14115.pdf'
url_code: 'https://github.com/wayveai/LingoQA'
url_dataset: 'https://github.com/wayveai/LingoQA?tab=readme-ov-file#download-data-and-annotations-'
url_video: 'https://www.canva.com/design/DAF-vlMT8vo/X7ynk_nv52t7jE7UpKlRBg/watch?utm_content=DAF-vlMT8vo&utm_campaign=designshare&utm_medium=link&utm_source=editor'
image:
  caption: ''
  focal_point: ''
  preview_only: false
featured: true
tags: [featured]

---
